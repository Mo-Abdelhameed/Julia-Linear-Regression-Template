{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: using StatsModels.formula in module Main conflicts with an existing identifier.\n",
      "WARNING: using StatsModels.schema in module Main conflicts with an existing identifier.\n"
     ]
    }
   ],
   "source": [
    "using Pkg\n",
    "using DataFrames\n",
    "using JSON\n",
    "using GLM \n",
    "using MLJ \n",
    "using MLJBase\n",
    "using CSV\n",
    "using Serialization\n",
    "using MLJScientificTypes\n",
    "using CategoricalArrays\n",
    "using JLD2\n",
    "using StatsBase\n",
    "using StatsModels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setting up directories\n",
    "ROOT_DIR = dirname(pwd())\n",
    "# Setting up directory and file paths\n",
    "MODEL_INPUTS_OUTPUTS = joinpath(ROOT_DIR, \"model_inputs_outputs\")\n",
    "INPUT_DIR = joinpath(MODEL_INPUTS_OUTPUTS, \"inputs\")\n",
    "INPUT_SCHEMA_DIR = joinpath(INPUT_DIR, \"schema\")\n",
    "DATA_DIR = joinpath(INPUT_DIR, \"data\")\n",
    "TRAIN_DIR = joinpath(DATA_DIR, \"training\")\n",
    "TEST_DIR = joinpath(DATA_DIR, \"testing\")\n",
    "MODEL_PATH = joinpath(MODEL_INPUTS_OUTPUTS, \"model\")\n",
    "MODEL_ARTIFACTS_PATH = joinpath(MODEL_PATH, \"artifacts\")\n",
    "OHE_ENCODER_FILE = joinpath(MODEL_ARTIFACTS_PATH, \"ohe.jld2\")\n",
    "PREDICTOR_DIR_PATH = joinpath(MODEL_ARTIFACTS_PATH, \"predictor\")\n",
    "PREDICTOR_FILE_PATH = joinpath(PREDICTOR_DIR_PATH, \"predictor.jld2\")\n",
    "IMPUTATION_FILE = joinpath(MODEL_ARTIFACTS_PATH, \"imputation.json\")\n",
    "TOP_CATEGORIES = joinpath(MODEL_ARTIFACTS_PATH, \"top_categories.json\")\n",
    "\n",
    "if !isdir(MODEL_ARTIFACTS_PATH)\n",
    "    mkdir(MODEL_ARTIFACTS_PATH)\n",
    "end\n",
    "if !isdir(PREDICTOR_DIR_PATH)\n",
    "    mkdir(PREDICTOR_DIR_PATH)\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"target\""
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Reading a schema from a JSON file and extracting features\n",
    "file_name = first(filter(x -> endswith(x, \"json\"), readdir(INPUT_SCHEMA_DIR)))\n",
    "schema_path = joinpath(INPUT_SCHEMA_DIR, file_name)\n",
    "schema = JSON.parsefile(schema_path)\n",
    "features = schema[\"features\"]\n",
    "\n",
    "# Identifying numeric, categorical, and nullable features\n",
    "numeric_features = String[]\n",
    "categorical_features = String[]\n",
    "nullable_features = String[]\n",
    "\n",
    "for f in features\n",
    "    if f[\"dataType\"] == \"CATEGORICAL\"\n",
    "        push!(categorical_features, f[\"name\"])\n",
    "    else\n",
    "        push!(numeric_features, f[\"name\"])\n",
    "    end\n",
    "    if f[\"nullable\"]\n",
    "        push!(nullable_features, f[\"name\"])\n",
    "    end\n",
    "end\n",
    "\n",
    "# Extracting ID and target features\n",
    "id_feature = schema[\"id\"][\"name\"]\n",
    "target_feature = schema[\"target\"][\"name\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div class=\"data-frame\"><p>5 rows × 4 columns</p><table class=\"data-frame\"><thead><tr><th></th><th>id</th><th>number</th><th>color</th><th>target</th></tr><tr><th></th><th title=\"String7\">String7</th><th title=\"Union{Missing, Float64}\">Float64?</th><th title=\"Union{Missing, String7}\">String7?</th><th title=\"Float64\">Float64</th></tr></thead><tbody><tr><th>1</th><td>YDDKTO</td><td><em>missing</em></td><td><em>missing</em></td><td>84.7411</td></tr><tr><th>2</th><td>FPLK2Z</td><td>3.3782</td><td>Red</td><td>26.2021</td></tr><tr><th>3</th><td>P2YCAP</td><td>2.248</td><td>Blue</td><td>112.355</td></tr><tr><th>4</th><td>IMT8XP</td><td>1.9806</td><td>Blue</td><td>109.826</td></tr><tr><th>5</th><td>5D9Q5F</td><td>0.5048</td><td>Red</td><td>1.0144</td></tr></tbody></table></div>"
      ],
      "text/latex": [
       "\\begin{tabular}{r|cccc}\n",
       "\t& id & number & color & target\\\\\n",
       "\t\\hline\n",
       "\t& String7 & Float64? & String7? & Float64\\\\\n",
       "\t\\hline\n",
       "\t1 & YDDKTO & \\emph{missing} & \\emph{missing} & 84.7411 \\\\\n",
       "\t2 & FPLK2Z & 3.3782 & Red & 26.2021 \\\\\n",
       "\t3 & P2YCAP & 2.248 & Blue & 112.355 \\\\\n",
       "\t4 & IMT8XP & 1.9806 & Blue & 109.826 \\\\\n",
       "\t5 & 5D9Q5F & 0.5048 & Red & 1.0144 \\\\\n",
       "\\end{tabular}\n"
      ],
      "text/plain": [
       "\u001b[1m5×4 DataFrame\u001b[0m\n",
       "\u001b[1m Row \u001b[0m│\u001b[1m id      \u001b[0m\u001b[1m number       \u001b[0m\u001b[1m color    \u001b[0m\u001b[1m target   \u001b[0m\n",
       "\u001b[1m     \u001b[0m│\u001b[90m String7 \u001b[0m\u001b[90m Float64?     \u001b[0m\u001b[90m String7? \u001b[0m\u001b[90m Float64  \u001b[0m\n",
       "─────┼───────────────────────────────────────────\n",
       "   1 │ YDDKTO  \u001b[90m missing      \u001b[0m\u001b[90m missing  \u001b[0m  84.7411\n",
       "   2 │ FPLK2Z         3.3782  Red        26.2021\n",
       "   3 │ P2YCAP         2.248   Blue      112.355\n",
       "   4 │ IMT8XP         1.9806  Blue      109.826\n",
       "   5 │ 5D9Q5F         0.5048  Red         1.0144"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Find the first CSV file in the TRAIN_DIR\n",
    "file_name = first(filter(x -> endswith(x, \".csv\"), readdir(TRAIN_DIR)))\n",
    "file_path = joinpath(TRAIN_DIR, file_name)\n",
    "\n",
    "# Read the CSV file into a DataFrame\n",
    "df = CSV.File(file_path) |> DataFrame\n",
    "\n",
    "# Display the first few rows of the DataFrame\n",
    "first(df, 5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imputing missing data\n",
    "imputation_values = Dict{String, Any}()\n",
    "\n",
    "for column in nullable_features\n",
    "    if column in numeric_features\n",
    "        value = median(skipmissing(df[!, column]))\n",
    "    else\n",
    "        value = mode(skipmissing(df[!, column]))\n",
    "    end\n",
    "    df[!, column] = coalesce.(df[!, column], value)\n",
    "    imputation_values[column] = value\n",
    "end\n",
    "\n",
    "# Serialize the imputation_values dictionary to a JSON file\n",
    "open(IMPUTATION_FILE, \"w\") do io\n",
    "    JSON.print(io, imputation_values)\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div class=\"data-frame\"><p>160 rows × 2 columns</p><table class=\"data-frame\"><thead><tr><th></th><th>number</th><th>color</th></tr><tr><th></th><th title=\"Float64\">Float64</th><th title=\"String7\">String7</th></tr></thead><tbody><tr><th>1</th><td>5.05815</td><td>Blue</td></tr><tr><th>2</th><td>3.3782</td><td>Red</td></tr><tr><th>3</th><td>2.248</td><td>Blue</td></tr><tr><th>4</th><td>1.9806</td><td>Blue</td></tr><tr><th>5</th><td>0.5048</td><td>Red</td></tr><tr><th>6</th><td>8.1929</td><td>Red</td></tr><tr><th>7</th><td>5.05815</td><td>Blue</td></tr><tr><th>8</th><td>1.1673</td><td>Red</td></tr><tr><th>9</th><td>1.5919</td><td>Red</td></tr><tr><th>10</th><td>0.1463</td><td>Green</td></tr><tr><th>11</th><td>5.842</td><td>Green</td></tr><tr><th>12</th><td>8.7992</td><td>Green</td></tr><tr><th>13</th><td>7.6324</td><td>Blue</td></tr><tr><th>14</th><td>2.9973</td><td>Blue</td></tr><tr><th>15</th><td>2.6222</td><td>Blue</td></tr><tr><th>16</th><td>6.0104</td><td>Red</td></tr><tr><th>17</th><td>5.05815</td><td>Blue</td></tr><tr><th>18</th><td>5.198</td><td>Green</td></tr><tr><th>19</th><td>4.8402</td><td>Red</td></tr><tr><th>20</th><td>4.5851</td><td>Blue</td></tr><tr><th>21</th><td>8.3826</td><td>Blue</td></tr><tr><th>22</th><td>1.981</td><td>Blue</td></tr><tr><th>23</th><td>4.2845</td><td>Blue</td></tr><tr><th>24</th><td>8.1262</td><td>Green</td></tr><tr><th>25</th><td>9.7708</td><td>Blue</td></tr><tr><th>26</th><td>5.5758</td><td>Blue</td></tr><tr><th>27</th><td>3.1924</td><td>Green</td></tr><tr><th>28</th><td>0.1486</td><td>Green</td></tr><tr><th>29</th><td>8.4439</td><td>Red</td></tr><tr><th>30</th><td>5.05815</td><td>Green</td></tr><tr><th>&vellip;</th><td>&vellip;</td><td>&vellip;</td></tr></tbody></table></div>"
      ],
      "text/latex": [
       "\\begin{tabular}{r|cc}\n",
       "\t& number & color\\\\\n",
       "\t\\hline\n",
       "\t& Float64 & String7\\\\\n",
       "\t\\hline\n",
       "\t1 & 5.05815 & Blue \\\\\n",
       "\t2 & 3.3782 & Red \\\\\n",
       "\t3 & 2.248 & Blue \\\\\n",
       "\t4 & 1.9806 & Blue \\\\\n",
       "\t5 & 0.5048 & Red \\\\\n",
       "\t6 & 8.1929 & Red \\\\\n",
       "\t7 & 5.05815 & Blue \\\\\n",
       "\t8 & 1.1673 & Red \\\\\n",
       "\t9 & 1.5919 & Red \\\\\n",
       "\t10 & 0.1463 & Green \\\\\n",
       "\t11 & 5.842 & Green \\\\\n",
       "\t12 & 8.7992 & Green \\\\\n",
       "\t13 & 7.6324 & Blue \\\\\n",
       "\t14 & 2.9973 & Blue \\\\\n",
       "\t15 & 2.6222 & Blue \\\\\n",
       "\t16 & 6.0104 & Red \\\\\n",
       "\t17 & 5.05815 & Blue \\\\\n",
       "\t18 & 5.198 & Green \\\\\n",
       "\t19 & 4.8402 & Red \\\\\n",
       "\t20 & 4.5851 & Blue \\\\\n",
       "\t21 & 8.3826 & Blue \\\\\n",
       "\t22 & 1.981 & Blue \\\\\n",
       "\t23 & 4.2845 & Blue \\\\\n",
       "\t24 & 8.1262 & Green \\\\\n",
       "\t25 & 9.7708 & Blue \\\\\n",
       "\t26 & 5.5758 & Blue \\\\\n",
       "\t27 & 3.1924 & Green \\\\\n",
       "\t28 & 0.1486 & Green \\\\\n",
       "\t29 & 8.4439 & Red \\\\\n",
       "\t30 & 5.05815 & Green \\\\\n",
       "\t$\\dots$ & $\\dots$ & $\\dots$ \\\\\n",
       "\\end{tabular}\n"
      ],
      "text/plain": [
       "\u001b[1m160×2 DataFrame\u001b[0m\n",
       "\u001b[1m Row \u001b[0m│\u001b[1m number  \u001b[0m\u001b[1m color   \u001b[0m\n",
       "\u001b[1m     \u001b[0m│\u001b[90m Float64 \u001b[0m\u001b[90m String7 \u001b[0m\n",
       "─────┼──────────────────\n",
       "   1 │ 5.05815  Blue\n",
       "   2 │ 3.3782   Red\n",
       "   3 │ 2.248    Blue\n",
       "   4 │ 1.9806   Blue\n",
       "   5 │ 0.5048   Red\n",
       "   6 │ 8.1929   Red\n",
       "   7 │ 5.05815  Blue\n",
       "   8 │ 1.1673   Red\n",
       "   9 │ 1.5919   Red\n",
       "  10 │ 0.1463   Green\n",
       "  11 │ 5.842    Green\n",
       "  ⋮  │    ⋮        ⋮\n",
       " 151 │ 7.1458   Blue\n",
       " 152 │ 6.0316   Red\n",
       " 153 │ 5.05815  Blue\n",
       " 154 │ 1.6807   Red\n",
       " 155 │ 7.4267   Blue\n",
       " 156 │ 4.3612   Green\n",
       " 157 │ 5.05815  Red\n",
       " 158 │ 8.2868   Red\n",
       " 159 │ 3.0087   Green\n",
       " 160 │ 4.9505   Green\n",
       "\u001b[36m        139 rows omitted\u001b[0m"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Saving the id and target columns in a different variable\n",
    "ids = df[!, Symbol(id_feature)]\n",
    "target = df[!, Symbol(target_feature)]\n",
    "\n",
    "# Dropping the id and target from the DataFrame\n",
    "select!(df, Not([Symbol(id_feature), Symbol(target_feature)]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "32"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Function to get top 3 categories\n",
    "function get_top_categories(df, features, n=3)\n",
    "    top_cats = Dict()\n",
    "    for feature in features\n",
    "        col_data = df[!, feature]\n",
    "        category_counts = countmap(col_data)\n",
    "        sorted_categories = sort(collect(category_counts), by=x->x[2], rev=true)\n",
    "        top_cats[feature] = [x[1] for x in sorted_categories[1:n]]\n",
    "    end\n",
    "    return top_cats\n",
    "end\n",
    "\n",
    "\n",
    "# Get top 3 categories for specific features\n",
    "top_categories = get_top_categories(df, categorical_features)\n",
    "\n",
    "# Function to one-hot encode only the top 3 categories\n",
    "function one_hot_top_categories!(df, top_categories)\n",
    "    for (feature, top_cats) in top_categories\n",
    "        for cat in top_cats\n",
    "            new_col_name = \"$(feature)_$(cat)\"\n",
    "            df[!, new_col_name] = df[!, feature] .== cat\n",
    "        end\n",
    "    end\n",
    "end\n",
    "\n",
    "# Apply one-hot encoding\n",
    "one_hot_top_categories!(df, top_categories)\n",
    "\n",
    "\n",
    "# Save top_categories to a JSON file\n",
    "json_content = JSON.json(top_categories)\n",
    "open(TOP_CATEGORIES, \"w\") do f\n",
    "    write(f, json_content)\n",
    "end\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Concatenate the new DataFrame with the existing 'df' DataFrame horizontally\n",
    "df = hcat(df, DataFrame(target = target))\n",
    "\n",
    "# Get all column names\n",
    "all_columns = names(df)\n",
    "\n",
    "# Remove the target variable to get only predictor variables\n",
    "predictor_columns = filter(x -> x != \"target\", all_columns)\n",
    "\n",
    "# Create Terms for predictors and response\n",
    "predictor_terms = [Term(Symbol(col)) for col in predictor_columns]\n",
    "response_term = Term(:target)\n",
    "\n",
    "# Create the formula\n",
    "formula_obj = FormulaTerm(response_term, sum(predictor_terms))\n",
    "\n",
    "# Create a Linear Regression model and train it\n",
    "model = lm(formula_obj, df)\n",
    "\n",
    "# Your model is now trained on all predictor variables in 'df'\n",
    "\n",
    "# BEGIN\n",
    "    # If you want to perform additional operations on the model, you can do so here\n",
    "    # For example, you can set hyperparameters, do cross-validation, etc.\n",
    "    # model = ...\n",
    "# END\n",
    "\n",
    "# Saving the model to use it for predictions\n",
    "save(PREDICTOR_FILE_PATH, \"model\", model)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Julia 1.9.3",
   "language": "julia",
   "name": "julia-1.9"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.9.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
