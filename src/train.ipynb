{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "using Suppressor\n",
    "@suppress begin\n",
    "    using Pkg\n",
    "    using DataFrames\n",
    "    using LazyJSON\n",
    "    using GLM \n",
    "    using MLJ \n",
    "    using MLJBase\n",
    "    using CSV\n",
    "    using Serialization\n",
    "    using MLJScientificTypes\n",
    "    using CategoricalArrays\n",
    "    using JLD2\n",
    "    using StatsBase\n",
    "    using StatsModels\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setting up directories\n",
    "ROOT_DIR = dirname(pwd())\n",
    "# Setting up directory and file paths\n",
    "MODEL_INPUTS_OUTPUTS = joinpath(ROOT_DIR, \"model_inputs_outputs\")\n",
    "INPUT_DIR = joinpath(MODEL_INPUTS_OUTPUTS, \"inputs\")\n",
    "INPUT_SCHEMA_DIR = joinpath(INPUT_DIR, \"schema\")\n",
    "DATA_DIR = joinpath(INPUT_DIR, \"data\")\n",
    "TRAIN_DIR = joinpath(DATA_DIR, \"training\")\n",
    "TEST_DIR = joinpath(DATA_DIR, \"testing\")\n",
    "MODEL_PATH = joinpath(MODEL_INPUTS_OUTPUTS, \"model\")\n",
    "MODEL_ARTIFACTS_PATH = joinpath(MODEL_PATH, \"artifacts\")\n",
    "OHE_ENCODER_FILE = joinpath(MODEL_ARTIFACTS_PATH, \"ohe.jld2\")\n",
    "PREDICTOR_DIR_PATH = joinpath(MODEL_ARTIFACTS_PATH, \"predictor\")\n",
    "PREDICTOR_FILE_PATH = joinpath(PREDICTOR_DIR_PATH, \"predictor.jld2\")\n",
    "IMPUTATION_FILE = joinpath(MODEL_ARTIFACTS_PATH, \"imputation.ser\")\n",
    "TOP_CATEGORIES = joinpath(MODEL_ARTIFACTS_PATH, \"top_categories.ser\")\n",
    "\n",
    "if !isdir(MODEL_ARTIFACTS_PATH)\n",
    "    mkdir(MODEL_ARTIFACTS_PATH)\n",
    "end\n",
    "if !isdir(PREDICTOR_DIR_PATH)\n",
    "    mkdir(PREDICTOR_DIR_PATH)\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"danceability\""
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Reading a schema from a JSON file and extracting features\n",
    "file_name = first(filter(x -> endswith(x, \"json\"), readdir(INPUT_SCHEMA_DIR)))\n",
    "schema_path = joinpath(INPUT_SCHEMA_DIR, file_name)\n",
    "schema_string = read(schema_path, String)  # Read file content as a string\n",
    "schema = LazyJSON.parse(schema_string)  # Parse using LazyJSON\n",
    "\n",
    "features = schema[\"features\"]\n",
    "\n",
    "# Identifying numeric, categorical, and nullable features\n",
    "numeric_features = String[]\n",
    "categorical_features = String[]\n",
    "nullable_features = String[]\n",
    "\n",
    "for f in features\n",
    "    if f[\"dataType\"] == \"CATEGORICAL\"\n",
    "        push!(categorical_features, f[\"name\"])\n",
    "    else\n",
    "        push!(numeric_features, f[\"name\"])\n",
    "    end\n",
    "    if f[\"nullable\"]\n",
    "        push!(nullable_features, f[\"name\"])\n",
    "    end\n",
    "end\n",
    "\n",
    "# Extracting ID and target features\n",
    "id_feature = schema[\"id\"][\"name\"]\n",
    "target_feature = schema[\"target\"][\"name\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div class=\"data-frame\"><p>5 rows × 20 columns (omitted printing of 13 columns)</p><table class=\"data-frame\"><thead><tr><th></th><th>id</th><th>energy</th><th>key</th><th>loudness</th><th>mode</th><th>speechiness</th><th>acousticness</th></tr><tr><th></th><th title=\"String31\">String31</th><th title=\"Float64\">Float64</th><th title=\"Int64\">Int64</th><th title=\"Float64\">Float64</th><th title=\"Int64\">Int64</th><th title=\"Float64\">Float64</th><th title=\"Float64\">Float64</th></tr></thead><tbody><tr><th>1</th><td>7BCer0V0I1CZDI6S6kYD44</td><td>0.838</td><td>2</td><td>-5.411</td><td>0</td><td>0.186</td><td>0.472</td></tr><tr><th>2</th><td>5Hqxu31lSOCdgMKxZvb9Mt</td><td>0.812</td><td>10</td><td>-4.21</td><td>0</td><td>0.0405</td><td>0.0107</td></tr><tr><th>3</th><td>4nSzw7BlbPsV5tKarOtO9W</td><td>0.903</td><td>2</td><td>-6.677</td><td>1</td><td>0.122</td><td>0.00419</td></tr><tr><th>4</th><td>2MYP61a4O2CcM9tEYwM0gf</td><td>0.589</td><td>1</td><td>-8.996</td><td>1</td><td>0.0909</td><td>0.00021</td></tr><tr><th>5</th><td>3XrzApq8R10O6WwNwMw8t4</td><td>0.241</td><td>5</td><td>-14.872</td><td>1</td><td>0.0323</td><td>0.89</td></tr></tbody></table></div>"
      ],
      "text/latex": [
       "\\begin{tabular}{r|cccccccc}\n",
       "\t& id & energy & key & loudness & mode & speechiness & acousticness & \\\\\n",
       "\t\\hline\n",
       "\t& String31 & Float64 & Int64 & Float64 & Int64 & Float64 & Float64 & \\\\\n",
       "\t\\hline\n",
       "\t1 & 7BCer0V0I1CZDI6S6kYD44 & 0.838 & 2 & -5.411 & 0 & 0.186 & 0.472 & $\\dots$ \\\\\n",
       "\t2 & 5Hqxu31lSOCdgMKxZvb9Mt & 0.812 & 10 & -4.21 & 0 & 0.0405 & 0.0107 & $\\dots$ \\\\\n",
       "\t3 & 4nSzw7BlbPsV5tKarOtO9W & 0.903 & 2 & -6.677 & 1 & 0.122 & 0.00419 & $\\dots$ \\\\\n",
       "\t4 & 2MYP61a4O2CcM9tEYwM0gf & 0.589 & 1 & -8.996 & 1 & 0.0909 & 0.00021 & $\\dots$ \\\\\n",
       "\t5 & 3XrzApq8R10O6WwNwMw8t4 & 0.241 & 5 & -14.872 & 1 & 0.0323 & 0.89 & $\\dots$ \\\\\n",
       "\\end{tabular}\n"
      ],
      "text/plain": [
       "\u001b[1m5×20 DataFrame\u001b[0m\n",
       "\u001b[1m Row \u001b[0m│\u001b[1m id                     \u001b[0m\u001b[1m energy  \u001b[0m\u001b[1m key   \u001b[0m\u001b[1m loudness \u001b[0m\u001b[1m mode  \u001b[0m\u001b[1m speechiness \u001b[0m\u001b[1m a\u001b[0m ⋯\n",
       "\u001b[1m     \u001b[0m│\u001b[90m String31               \u001b[0m\u001b[90m Float64 \u001b[0m\u001b[90m Int64 \u001b[0m\u001b[90m Float64  \u001b[0m\u001b[90m Int64 \u001b[0m\u001b[90m Float64     \u001b[0m\u001b[90m F\u001b[0m ⋯\n",
       "─────┼──────────────────────────────────────────────────────────────────────────\n",
       "   1 │ 7BCer0V0I1CZDI6S6kYD44    0.838      2    -5.411      0       0.186     ⋯\n",
       "   2 │ 5Hqxu31lSOCdgMKxZvb9Mt    0.812     10    -4.21       0       0.0405\n",
       "   3 │ 4nSzw7BlbPsV5tKarOtO9W    0.903      2    -6.677      1       0.122\n",
       "   4 │ 2MYP61a4O2CcM9tEYwM0gf    0.589      1    -8.996      1       0.0909\n",
       "   5 │ 3XrzApq8R10O6WwNwMw8t4    0.241      5   -14.872      1       0.0323    ⋯\n",
       "\u001b[36m                                                              14 columns omitted\u001b[0m"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Find the first CSV file in the TRAIN_DIR\n",
    "file_name = first(filter(x -> endswith(x, \".csv\"), readdir(TRAIN_DIR)))\n",
    "file_path = joinpath(TRAIN_DIR, file_name)\n",
    "\n",
    "# Read the CSV file into a DataFrame\n",
    "df = CSV.File(file_path) |> DataFrame\n",
    "\n",
    "# Display the first few rows of the DataFrame\n",
    "first(df, 5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imputing missing data\n",
    "imputation_values = Dict{String, Any}()\n",
    "\n",
    "for column in nullable_features\n",
    "    if column in numeric_features\n",
    "        value = median(skipmissing(df[!, column]))\n",
    "    else\n",
    "        value = mode(skipmissing(df[!, column]))\n",
    "    end\n",
    "    df[!, column] = coalesce.(df[!, column], value)\n",
    "    imputation_values[column] = value\n",
    "end\n",
    "\n",
    "# Serialize the imputation_values dictionary to a binary file\n",
    "open(IMPUTATION_FILE, \"w\") do io\n",
    "    serialize(io, imputation_values)\n",
    "end\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div class=\"data-frame\"><p>7,144 rows × 18 columns (omitted printing of 10 columns)</p><table class=\"data-frame\"><thead><tr><th></th><th>energy</th><th>key</th><th>loudness</th><th>mode</th><th>speechiness</th><th>acousticness</th><th>instrumentalness</th><th>liveness</th></tr><tr><th></th><th title=\"Float64\">Float64</th><th title=\"Int64\">Int64</th><th title=\"Float64\">Float64</th><th title=\"Int64\">Int64</th><th title=\"Float64\">Float64</th><th title=\"Float64\">Float64</th><th title=\"Float64\">Float64</th><th title=\"Float64\">Float64</th></tr></thead><tbody><tr><th>1</th><td>0.838</td><td>2</td><td>-5.411</td><td>0</td><td>0.186</td><td>0.472</td><td>0.0</td><td>0.605</td></tr><tr><th>2</th><td>0.812</td><td>10</td><td>-4.21</td><td>0</td><td>0.0405</td><td>0.0107</td><td>3.11e-5</td><td>0.251</td></tr><tr><th>3</th><td>0.903</td><td>2</td><td>-6.677</td><td>1</td><td>0.122</td><td>0.00419</td><td>0.0</td><td>0.0538</td></tr><tr><th>4</th><td>0.589</td><td>1</td><td>-8.996</td><td>1</td><td>0.0909</td><td>0.00021</td><td>0.00124</td><td>0.0665</td></tr><tr><th>5</th><td>0.241</td><td>5</td><td>-14.872</td><td>1</td><td>0.0323</td><td>0.89</td><td>0.00386</td><td>0.141</td></tr><tr><th>6</th><td>0.466</td><td>1</td><td>-15.673</td><td>1</td><td>0.0555</td><td>0.314</td><td>0.0234</td><td>0.129</td></tr><tr><th>7</th><td>0.646</td><td>11</td><td>-5.509</td><td>1</td><td>0.0839</td><td>0.376</td><td>0.0</td><td>0.0705</td></tr><tr><th>8</th><td>0.803</td><td>0</td><td>-4.45</td><td>1</td><td>0.0777</td><td>0.0161</td><td>0.0</td><td>0.667</td></tr><tr><th>9</th><td>0.534</td><td>0</td><td>-6.953</td><td>1</td><td>0.0274</td><td>0.709</td><td>0.0</td><td>0.103</td></tr><tr><th>10</th><td>0.623</td><td>9</td><td>-10.593</td><td>0</td><td>0.0363</td><td>0.203</td><td>0.0</td><td>0.0833</td></tr><tr><th>11</th><td>0.472</td><td>8</td><td>-9.499</td><td>1</td><td>0.0257</td><td>0.415</td><td>1.68e-5</td><td>0.892</td></tr><tr><th>12</th><td>0.626</td><td>2</td><td>-15.257</td><td>0</td><td>0.0842</td><td>0.135</td><td>0.0</td><td>0.33</td></tr><tr><th>13</th><td>0.312</td><td>4</td><td>-13.961</td><td>1</td><td>0.0276</td><td>0.565</td><td>0.0</td><td>0.114</td></tr><tr><th>14</th><td>0.24</td><td>2</td><td>-16.754</td><td>1</td><td>0.0261</td><td>0.653</td><td>0.458</td><td>0.134</td></tr><tr><th>15</th><td>0.867</td><td>9</td><td>-13.313</td><td>0</td><td>0.158</td><td>0.0207</td><td>8.49e-5</td><td>0.106</td></tr><tr><th>16</th><td>0.594</td><td>0</td><td>-12.013</td><td>1</td><td>0.0248</td><td>0.237</td><td>0.0</td><td>0.147</td></tr><tr><th>17</th><td>0.505</td><td>1</td><td>-7.345</td><td>1</td><td>0.0829</td><td>0.311</td><td>7.49e-5</td><td>0.0777</td></tr><tr><th>18</th><td>0.241</td><td>7</td><td>-12.71</td><td>1</td><td>0.0264</td><td>0.529</td><td>0.0343</td><td>0.216</td></tr><tr><th>19</th><td>0.652</td><td>1</td><td>-13.018</td><td>1</td><td>0.114</td><td>0.0647</td><td>0.0</td><td>0.343</td></tr><tr><th>20</th><td>0.573</td><td>2</td><td>-13.222</td><td>1</td><td>0.0363</td><td>0.0259</td><td>0.0</td><td>0.112</td></tr><tr><th>21</th><td>0.856</td><td>11</td><td>-6.482</td><td>0</td><td>0.0287</td><td>0.429</td><td>0.823</td><td>0.266</td></tr><tr><th>22</th><td>0.886</td><td>10</td><td>-2.602</td><td>0</td><td>0.289</td><td>0.0938</td><td>2.92e-6</td><td>0.105</td></tr><tr><th>23</th><td>0.399</td><td>9</td><td>-14.377</td><td>1</td><td>0.0416</td><td>0.573</td><td>0.000422</td><td>0.13</td></tr><tr><th>24</th><td>0.279</td><td>0</td><td>-10.604</td><td>1</td><td>0.025</td><td>0.498</td><td>0.0</td><td>0.126</td></tr><tr><th>&vellip;</th><td>&vellip;</td><td>&vellip;</td><td>&vellip;</td><td>&vellip;</td><td>&vellip;</td><td>&vellip;</td><td>&vellip;</td><td>&vellip;</td></tr></tbody></table></div>"
      ],
      "text/latex": [
       "\\begin{tabular}{r|ccccccccc}\n",
       "\t& energy & key & loudness & mode & speechiness & acousticness & instrumentalness & liveness & \\\\\n",
       "\t\\hline\n",
       "\t& Float64 & Int64 & Float64 & Int64 & Float64 & Float64 & Float64 & Float64 & \\\\\n",
       "\t\\hline\n",
       "\t1 & 0.838 & 2 & -5.411 & 0 & 0.186 & 0.472 & 0.0 & 0.605 & $\\dots$ \\\\\n",
       "\t2 & 0.812 & 10 & -4.21 & 0 & 0.0405 & 0.0107 & 3.11e-5 & 0.251 & $\\dots$ \\\\\n",
       "\t3 & 0.903 & 2 & -6.677 & 1 & 0.122 & 0.00419 & 0.0 & 0.0538 & $\\dots$ \\\\\n",
       "\t4 & 0.589 & 1 & -8.996 & 1 & 0.0909 & 0.00021 & 0.00124 & 0.0665 & $\\dots$ \\\\\n",
       "\t5 & 0.241 & 5 & -14.872 & 1 & 0.0323 & 0.89 & 0.00386 & 0.141 & $\\dots$ \\\\\n",
       "\t6 & 0.466 & 1 & -15.673 & 1 & 0.0555 & 0.314 & 0.0234 & 0.129 & $\\dots$ \\\\\n",
       "\t7 & 0.646 & 11 & -5.509 & 1 & 0.0839 & 0.376 & 0.0 & 0.0705 & $\\dots$ \\\\\n",
       "\t8 & 0.803 & 0 & -4.45 & 1 & 0.0777 & 0.0161 & 0.0 & 0.667 & $\\dots$ \\\\\n",
       "\t9 & 0.534 & 0 & -6.953 & 1 & 0.0274 & 0.709 & 0.0 & 0.103 & $\\dots$ \\\\\n",
       "\t10 & 0.623 & 9 & -10.593 & 0 & 0.0363 & 0.203 & 0.0 & 0.0833 & $\\dots$ \\\\\n",
       "\t11 & 0.472 & 8 & -9.499 & 1 & 0.0257 & 0.415 & 1.68e-5 & 0.892 & $\\dots$ \\\\\n",
       "\t12 & 0.626 & 2 & -15.257 & 0 & 0.0842 & 0.135 & 0.0 & 0.33 & $\\dots$ \\\\\n",
       "\t13 & 0.312 & 4 & -13.961 & 1 & 0.0276 & 0.565 & 0.0 & 0.114 & $\\dots$ \\\\\n",
       "\t14 & 0.24 & 2 & -16.754 & 1 & 0.0261 & 0.653 & 0.458 & 0.134 & $\\dots$ \\\\\n",
       "\t15 & 0.867 & 9 & -13.313 & 0 & 0.158 & 0.0207 & 8.49e-5 & 0.106 & $\\dots$ \\\\\n",
       "\t16 & 0.594 & 0 & -12.013 & 1 & 0.0248 & 0.237 & 0.0 & 0.147 & $\\dots$ \\\\\n",
       "\t17 & 0.505 & 1 & -7.345 & 1 & 0.0829 & 0.311 & 7.49e-5 & 0.0777 & $\\dots$ \\\\\n",
       "\t18 & 0.241 & 7 & -12.71 & 1 & 0.0264 & 0.529 & 0.0343 & 0.216 & $\\dots$ \\\\\n",
       "\t19 & 0.652 & 1 & -13.018 & 1 & 0.114 & 0.0647 & 0.0 & 0.343 & $\\dots$ \\\\\n",
       "\t20 & 0.573 & 2 & -13.222 & 1 & 0.0363 & 0.0259 & 0.0 & 0.112 & $\\dots$ \\\\\n",
       "\t21 & 0.856 & 11 & -6.482 & 0 & 0.0287 & 0.429 & 0.823 & 0.266 & $\\dots$ \\\\\n",
       "\t22 & 0.886 & 10 & -2.602 & 0 & 0.289 & 0.0938 & 2.92e-6 & 0.105 & $\\dots$ \\\\\n",
       "\t23 & 0.399 & 9 & -14.377 & 1 & 0.0416 & 0.573 & 0.000422 & 0.13 & $\\dots$ \\\\\n",
       "\t24 & 0.279 & 0 & -10.604 & 1 & 0.025 & 0.498 & 0.0 & 0.126 & $\\dots$ \\\\\n",
       "\t$\\dots$ & $\\dots$ & $\\dots$ & $\\dots$ & $\\dots$ & $\\dots$ & $\\dots$ & $\\dots$ & $\\dots$ &  \\\\\n",
       "\\end{tabular}\n"
      ],
      "text/plain": [
       "\u001b[1m7144×18 DataFrame\u001b[0m\n",
       "\u001b[1m  Row \u001b[0m│\u001b[1m energy  \u001b[0m\u001b[1m key   \u001b[0m\u001b[1m loudness \u001b[0m\u001b[1m mode  \u001b[0m\u001b[1m speechiness \u001b[0m\u001b[1m acousticness \u001b[0m\u001b[1m instrument\u001b[0m ⋯\n",
       "\u001b[1m      \u001b[0m│\u001b[90m Float64 \u001b[0m\u001b[90m Int64 \u001b[0m\u001b[90m Float64  \u001b[0m\u001b[90m Int64 \u001b[0m\u001b[90m Float64     \u001b[0m\u001b[90m Float64      \u001b[0m\u001b[90m Float64   \u001b[0m ⋯\n",
       "──────┼─────────────────────────────────────────────────────────────────────────\n",
       "    1 │   0.838      2    -5.411      0       0.186       0.472             0. ⋯\n",
       "    2 │   0.812     10    -4.21       0       0.0405      0.0107            3.\n",
       "    3 │   0.903      2    -6.677      1       0.122       0.00419           0.\n",
       "    4 │   0.589      1    -8.996      1       0.0909      0.00021           0.\n",
       "    5 │   0.241      5   -14.872      1       0.0323      0.89              0. ⋯\n",
       "    6 │   0.466      1   -15.673      1       0.0555      0.314             0.\n",
       "    7 │   0.646     11    -5.509      1       0.0839      0.376             0.\n",
       "    8 │   0.803      0    -4.45       1       0.0777      0.0161            0.\n",
       "  ⋮   │    ⋮       ⋮       ⋮        ⋮         ⋮            ⋮               ⋮   ⋱\n",
       " 7138 │   0.693      3    -7.02       1       0.289       0.0747            0. ⋯\n",
       " 7139 │   0.794      5    -3.383      1       0.0292      0.475             0.\n",
       " 7140 │   0.559      7   -11.346      1       0.0394      0.242             0.\n",
       " 7141 │   0.778      7    -6.707      0       0.0294      0.00756           0.\n",
       " 7142 │   0.45       4   -12.911      0       0.0442      0.0656            0. ⋯\n",
       " 7143 │   0.674      7   -10.34       1       0.0644      0.7               0.\n",
       " 7144 │   0.624      4    -5.556      1       0.179       0.000185          6.\n",
       "\u001b[36m                                                12 columns and 7129 rows omitted\u001b[0m"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Saving the id and target columns in a different variable\n",
    "ids = df[!, Symbol(id_feature)]\n",
    "target = df[!, Symbol(target_feature)]\n",
    "\n",
    "# Dropping the id and target from the DataFrame\n",
    "select!(df, Not([Symbol(id_feature), Symbol(target_feature)]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to get top 3 categories\n",
    "function get_top_categories(df, features, n=3)\n",
    "    top_cats = Dict()\n",
    "    for feature in features\n",
    "        col_data = df[!, feature]\n",
    "        category_counts = countmap(col_data)\n",
    "        sorted_categories = sort(collect(category_counts), by=x->x[2], rev=true)\n",
    "        \n",
    "        # Take minimum between n and the number of unique categories\n",
    "        num_categories = min(n, length(sorted_categories))\n",
    "        \n",
    "        top_cats[feature] = [x[1] for x in sorted_categories[1:num_categories]]\n",
    "    end\n",
    "    return top_cats\n",
    "end\n",
    "\n",
    "\n",
    "\n",
    "# Get top 3 categories for specific features\n",
    "top_categories = get_top_categories(df, categorical_features)\n",
    "\n",
    "# Function to one-hot encode only the top 3 categories\n",
    "function one_hot_top_categories!(df, top_categories)\n",
    "    for (feature, top_cats) in top_categories\n",
    "        if length(top_cats) == 2  # Handle the binary case\n",
    "            # Assuming the first category in top_cats is treated as 'true'\n",
    "            new_col_name = \"$(feature)_binary\"\n",
    "            df[!, new_col_name] = df[!, feature] .== top_cats[1]\n",
    "        else  # Handle the general case\n",
    "            for cat in top_cats\n",
    "                new_col_name = \"$(feature)_$(cat)\"\n",
    "                df[!, new_col_name] = df[!, feature] .== cat\n",
    "            end\n",
    "        end\n",
    "        select!(df, Not(Symbol(feature)))  # Drop the original feature column\n",
    "    end\n",
    "end\n",
    "\n",
    "\n",
    "\n",
    "# Apply one-hot encoding\n",
    "one_hot_top_categories!(df, top_categories)\n",
    "\n",
    "\n",
    "\n",
    "# Serialize the imputation_values dictionary to a binary file\n",
    "open(TOP_CATEGORIES, \"w\") do io\n",
    "    serialize(io, top_categories)\n",
    "end\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Concatenate the new DataFrame with the existing 'df' DataFrame horizontally\n",
    "df = hcat(df, DataFrame(target = target))\n",
    "\n",
    "# Get all column names\n",
    "all_columns = names(df)\n",
    "\n",
    "# Remove the target variable to get only predictor variables\n",
    "predictor_columns = filter(x -> x != \"target\", all_columns)\n",
    "\n",
    "# Create Terms for predictors and response\n",
    "predictor_terms = [Term(Symbol(col)) for col in predictor_columns]\n",
    "response_term = Term(:target)\n",
    "\n",
    "# Create the formula\n",
    "formula_obj = FormulaTerm(response_term, sum(predictor_terms))\n",
    "\n",
    "# Create a Linear Regression model and train it\n",
    "model = lm(formula_obj, df)\n",
    "\n",
    "# Your model is now trained on all predictor variables in 'df'\n",
    "\n",
    "# BEGIN\n",
    "    # If you want to perform additional operations on the model, you can do so here\n",
    "    # For example, you can set hyperparameters, do cross-validation, etc.\n",
    "    # model = ...\n",
    "# END\n",
    "\n",
    "# Saving the model to use it for predictions\n",
    "save(PREDICTOR_FILE_PATH, \"model\", model)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Julia 1.9.3",
   "language": "julia",
   "name": "julia-1.9"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.9.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
